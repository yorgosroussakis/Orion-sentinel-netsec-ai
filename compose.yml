# Orion Sentinel NetSec Node - Main Compose File
# Production-ready network security monitoring for Raspberry Pi 5 + NVMe HAT
#
# This compose file provides profile-based deployment for the NetSec Pi sensor:
#
# Profiles:
#   - netsec-minimal: Core NSM sensor (Suricata + Promtail + Node Exporter)
#   - netsec-plus-evebox: Core NSM + EveBox UI for local analysis
#   - netsec-debug: Debug toolbox container (tcpdump, dig, curl, etc.)
#   - netsec-tools: NetSec analysis tools (CyberChef + ntopng)
#   - ai: AI detection services (SOAR, Inventory, Health Score, etc.) - legacy
#
# Production Deployment (recommended):
#   docker compose --profile netsec-minimal up -d
#
# With local EveBox UI:
#   docker compose --profile netsec-plus-evebox up -d
#
# With debug tools:
#   docker compose --profile netsec-minimal --profile netsec-debug up -d
#
# With NetSec analysis tools (CyberChef, ntopng):
#   docker compose --profile netsec-minimal --profile netsec-tools up -d
#
# Legacy full stack (AI services on NetSec Pi):
#   docker compose --profile netsec-minimal --profile ai up -d
#
# IMPORTANT: NVMe Storage
# ========================
# This stack requires NVMe storage mounted at /mnt/orion-nvme-netsec
# Run ./scripts/check-nvme.sh before starting services
# See docs/architecture-netsec.md for setup instructions

# Note: 'version' key is obsolete in modern Docker Compose and has been removed

services:
  # ============================================================================
  # PROFILE: netsec-minimal
  # Core Network Security Monitoring - Production Sensor
  # ============================================================================

  # Suricata IDS - Passive network monitoring on mirrored/SPAN traffic
  #
  # Why network_mode: host?
  # - Suricata needs direct access to physical network interfaces for packet capture
  # - AF_PACKET mode requires binding to specific interface (e.g., eth0, eth1)
  # - Bridge networking would only see container traffic, not mirrored traffic
  #
  # Required capabilities:
  # - NET_ADMIN: Create AF_PACKET sockets and manage network interfaces
  # - NET_RAW: Access raw packets for IDS inspection
  # - SYS_NICE: Adjust thread priorities for performance tuning (optional)
  #
  # Security: All other capabilities are dropped for least privilege
  #
  # NVMe-first storage:
  # - Config, logs, and rules all persist on NVMe
  # - Container /etc/suricata is writable for entrypoint to function
  # - Run scripts/netsec-sync-config.sh to initialize NVMe config from repo template
  suricata:
    image: jasonish/suricata:7.0.2  # ARM64-compatible, well-maintained
    container_name: orion-netsec-suricata
    profiles: ["netsec-minimal", "netsec-plus-evebox"]
    network_mode: host
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - SYS_NICE
    cap_drop:
      - ALL
    environment:
      # Timezone for log timestamps
      - TZ=${TZ:-Europe/Amsterdam}
      # IMPORTANT: Set NETSEC_INTERFACE in .env to your mirrored traffic interface
      # Examples: eth0, eth1, enx00e04c68xxxx (USB Ethernet)
      # Verify with: ip link show
      - SURICATA_OPTIONS=--af-packet=${NETSEC_INTERFACE:-eth1}
    volumes:
      # NVMe-first storage: All Suricata data persists on NVMe
      # NOTE: /etc/suricata must NOT be read-only to allow entrypoint to function
      # Config on NVMe (writable - entrypoint may modify)
      - ${NVME_MOUNT:-/mnt/orion-nvme-netsec}/suricata/etc:/etc/suricata
      # Logs on NVMe (avoid microSD wear)
      - ${NVME_MOUNT:-/mnt/orion-nvme-netsec}/suricata/logs:/var/log/suricata
      # Rules and lib data on NVMe (for suricata-update persistence)
      - ${NVME_MOUNT:-/mnt/orion-nvme-netsec}/suricata/lib:/var/lib/suricata

      # Optional: PCAP storage (enable in suricata.yaml if needed)
      # Warning: PCAPs consume significant disk space
      # - ${NVME_MOUNT:-/mnt/orion-nvme-netsec}/suricata/pcaps:/var/log/suricata/pcap
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Promtail - Ships logs from Suricata to Loki (CoreSrv or local)
  #
  # In production (SPoG mode):
  # - LOKI_URL points to CoreSrv Loki (e.g., http://192.168.x.x:3100)
  # - Promtail ships Suricata eve.json and optional system logs to CoreSrv
  #
  # In dev/lab mode (standalone):
  # - LOKI_URL=http://loki:3100 (local Loki container)
  # - Use docker-compose.local-observability.yml for local stack
  #
  # Labels applied (for Loki filtering):
  # - orion_node_role: netsec
  # - orion_node_name: from .env (e.g., netsec-pi-01)
  # - app: suricata
  # - stream: eve-json, fast, stats, etc.
  promtail:
    image: grafana/promtail:2.9.3
    container_name: orion-netsec-promtail
    profiles: ["netsec-minimal", "netsec-plus-evebox"]
    environment:
      # Loki endpoint (CoreSrv in production, local in dev)
      - LOKI_URL=${LOKI_URL:-http://loki:3100}

      # Node identification for Loki labels
      - ORION_NODE_ROLE=${ORION_NODE_ROLE:-netsec}
      - ORION_NODE_NAME=${ORION_NODE_NAME:-netsec-pi-01}
      - HOSTNAME=${HOSTNAME:-netsec-pi-01}
      - TZ=${TZ:-Europe/Amsterdam}
    volumes:
      # Promtail config with environment variable expansion
      - ./config/promtail/promtail-config.yml:/etc/promtail/config.yml:ro

      # Read Suricata logs from NVMe (read-only)
      - ${NVME_MOUNT:-/mnt/orion-nvme-netsec}/suricata/logs:/var/log/suricata:ro

      # Optional: Ship host system logs
      # Uncomment to include syslog, auth.log, etc.
      # - /var/log:/host/logs:ro
    command: -config.file=/etc/promtail/config.yml -config.expand-env=true
    restart: unless-stopped
    networks:
      - orion-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Node Exporter - System metrics for Prometheus (on CoreSrv)
  #
  # Exposes metrics on configurable port (default 19100) for CoreSrv Prometheus to scrape:
  # - CPU usage per core
  # - Memory usage and swap
  # - Disk I/O and usage (including NVMe)
  # - Network I/O per interface
  # - System uptime and load average
  #
  # Port note: Default is 19100 to avoid conflicts with other node-exporters on the network.
  # Set NODE_EXPORTER_PORT in .env to change.
  #
  # Security: Read-only access to host filesystems
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: orion-netsec-node-exporter
    profiles: ["netsec-minimal", "netsec-plus-evebox"]
    command:
      - '--path.rootfs=/host'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      - '--collector.netclass.ignored-devices=^(veth.*|br-.*|docker.*)$$'
    volumes:
      - /:/host:ro,rslave
    ports:
      - "${NODE_EXPORTER_PORT:-19100}:9100"
    restart: unless-stopped
    networks:
      - orion-network
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================================
  # PROFILE: netsec-plus-evebox
  # Optional: Local EveBox UI for Suricata Alert Analysis
  # ============================================================================

  # EveBox - Web UI for browsing Suricata alerts locally
  #
  # Purpose:
  # - Local troubleshooting and alert analysis
  # - Interactive alert review without Grafana
  # - Useful for quick investigations on the NetSec Pi itself
  #
  # Not required in production:
  # - CoreSrv Grafana provides primary alerting interface
  # - Use this profile only when needed for local analysis
  #
  # Access: http://netsec-pi-ip:5636
  evebox:
    image: jasonish/evebox:latest
    container_name: orion-netsec-evebox
    profiles: ["netsec-plus-evebox"]
    environment:
      - EVEBOX_HTTP_TLS_ENABLED=false
    volumes:
      # Read Suricata eve.json from NVMe (read-only)
      - ${NVME_MOUNT:-/mnt/orion-nvme-netsec}/suricata/logs:/var/log/suricata:ro
    ports:
      - "${EVEBOX_PORT:-5636}:5636"
    command:
      - -vv
      - --input
      - /var/log/suricata/eve.json
      - --host
      - 0.0.0.0
      - --port
      - "5636"
    restart: unless-stopped
    depends_on:
      - suricata
    networks:
      - orion-network
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================================
  # PROFILE: netsec-debug
  # Optional: Debug Toolbox for Network Troubleshooting
  # ============================================================================

  # Debug Toolbox - Network diagnostic utilities
  #
  # Included tools:
  # - tcpdump: Packet capture and analysis
  # - dig/nslookup: DNS debugging
  # - curl/wget: HTTP testing
  # - netcat: Port testing and raw TCP/UDP
  # - ping/traceroute: Connectivity testing
  # - ip/ss/netstat: Network interface inspection
  #
  # Usage:
  #   docker exec -it orion-netsec-debug /bin/sh
  #   tcpdump -i eth0 -nn 'port 53'
  #   dig @8.8.8.8 google.com
  #   curl -v http://192.168.1.1
  #
  # Security: Runs with NET_ADMIN for packet capture
  debug-toolbox:
    image: nicolaka/netshoot:latest
    container_name: orion-netsec-debug
    profiles: ["netsec-debug"]
    network_mode: host
    cap_add:
      - NET_ADMIN
      - NET_RAW
    cap_drop:
      - ALL
    command: sleep infinity
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================================
  # PROFILE: netsec-tools
  # Network Security Analysis Tools (CyberChef + ntopng)
  # ============================================================================
  #
  # NOTE: Port Conflict Warning
  # CyberChef defaults to port 8000, which conflicts with the AI profile's API service.
  # If you need to use both profiles together, change CYBERCHEF_PORT in .env:
  #   CYBERCHEF_PORT=8080  # or another available port

  # CyberChef - Data transformation and analysis tool
  #
  # Purpose:
  # - Decode/encode data (Base64, hex, URL encoding, etc.)
  # - Parse and analyze network payloads
  # - Extract IOCs from logs and alerts
  # - Convert between data formats
  # - Decrypt/encrypt test data
  #
  # Access: http://netsec-pi-ip:8000 (LAN-only)
  # For SSH tunnel: change ports binding to 127.0.0.1 in compose.yml
  #
  # Security: No authentication, LAN-only deployment recommended
  # DO NOT expose to the internet
  cyberchef:
    image: mpepping/cyberchef:latest
    container_name: orion-netsec-cyberchef
    profiles: ["netsec-tools"]
    ports:
      - "${CYBERCHEF_PORT:-8000}:8000"
    restart: unless-stopped
    networks:
      - orion-network
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    labels:
      # Promtail labels for log shipping (if needed)
      orion.node.role: "netsec"
      orion.node.name: "${ORION_NODE_NAME:-netsec-pi-01}"
      orion.service: "cyberchef"

  # Redis - Required for ntopng
  #
  # Purpose: Caching and data operations for ntopng
  # Note: ntopng uses host networking, so Redis must expose port on host
  redis:
    image: redis:7-alpine
    container_name: orion-netsec-redis
    profiles: ["netsec-tools"]
    command: redis-server --appendonly no --save ""
    ports:
      - "127.0.0.1:6379:6379"
    volumes:
      - redis-data:/data
    restart: unless-stopped
    networks:
      - orion-network
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    labels:
      orion.node.role: "netsec"
      orion.node.name: "${ORION_NODE_NAME:-netsec-pi-01}"
      orion.service: "redis"

  # ntopng - Network traffic analysis and flow monitoring
  #
  # Purpose:
  # - Real-time traffic statistics and visualization
  # - Top talkers, protocols, and bandwidth usage
  # - Historical traffic analysis
  # - Network security insights
  # - Layer 7 protocol detection
  #
  # Why network_mode: host?
  # - ntopng needs direct access to the physical interface for packet capture
  # - AF_PACKET mode requires binding to a specific interface (eth1)
  # - Bridge networking would only see container traffic, not mirrored traffic
  # - Redis connection: Connects to Redis on localhost:6379 (Redis exposes port to host)
  #
  # Access: http://netsec-pi-ip:3000 (LAN-only)
  # Default login disabled (--disable-login in ntopng.conf)
  #
  # Security: No authentication by default, LAN-only deployment
  # To enable authentication: Edit stacks/tools/ntopng/ntopng.conf,
  # remove the --disable-login line, then restart: docker compose --profile netsec-tools restart ntopng
  ntopng:
    image: ntop/ntopng:stable
    container_name: orion-netsec-ntopng
    profiles: ["netsec-tools"]
    network_mode: host
    cap_add:
      - NET_ADMIN
      - NET_RAW
    cap_drop:
      - ALL
    environment:
      - TZ=${TZ:-Europe/Amsterdam}
    volumes:
      # ntopng configuration (with interface and local networks)
      - ./stacks/tools/ntopng/ntopng.conf:/etc/ntopng/ntopng.conf:ro

      # Data directory for historical statistics (NVMe-backed for performance)
      - ${NVME_MOUNT:-/mnt/orion-nvme-netsec}/ntopng:/var/lib/ntopng
    restart: unless-stopped
    depends_on:
      - redis
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      orion.node.role: "netsec"
      orion.node.name: "${ORION_NODE_NAME:-netsec-pi-01}"
      orion.service: "ntopng"

  # ============================================================================
  # PROFILE: ai
  # AI Detection & Response Layer
  # ============================================================================

  # SOAR Service - Security Orchestration & Automated Response
  soar:
    build:
      context: .
      dockerfile: stacks/ai/Dockerfile
    image: orion-ai:latest
    container_name: orion-soar
    profiles: ["ai"]
    command: python -m orion_ai.soar.service
    environment:
      - LOKI_URL=${LOKI_URL}
      - SOAR_DRY_RUN=${SOAR_DRY_RUN:-1}
      - SOAR_POLL_INTERVAL=${SOAR_POLL_INTERVAL:-60}
      - SOAR_PLAYBOOKS_FILE=/config/playbooks.yml
      - SOAR_ALLOW_EMPTY_PLAYBOOKS=${SOAR_ALLOW_EMPTY_PLAYBOOKS:-0}
      - PIHOLE_URL=${PIHOLE_URL}
      - PIHOLE_API_KEY=${PIHOLE_API_KEY}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # Notification settings
      - NOTIFY_SMTP_HOST=${NOTIFY_SMTP_HOST}
      - NOTIFY_SMTP_PORT=${NOTIFY_SMTP_PORT}
      - NOTIFY_SMTP_USER=${NOTIFY_SMTP_USER}
      - NOTIFY_SMTP_PASS=${NOTIFY_SMTP_PASS}
      - NOTIFY_EMAIL_FROM=${NOTIFY_EMAIL_FROM}
      - NOTIFY_EMAIL_TO=${NOTIFY_EMAIL_TO}
      - NOTIFY_SIGNAL_ENABLED=${NOTIFY_SIGNAL_ENABLED:-false}
      - NOTIFY_TELEGRAM_ENABLED=${NOTIFY_TELEGRAM_ENABLED:-false}
    volumes:
      - ./config:/config:ro
      - soar-data:/data
    restart: unless-stopped
    networks:
      - orion-network

  # Device Inventory Service - Track and fingerprint network devices
  inventory:
    image: orion-ai:latest
    container_name: orion-inventory
    profiles: ["ai"]
    command: python -m orion_ai.inventory.service
    environment:
      - LOKI_URL=${LOKI_URL}
      - INVENTORY_POLL_INTERVAL=${INVENTORY_POLL_INTERVAL:-300}
      - INVENTORY_DB_PATH=/data/inventory.db
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # Threat Intel settings
      - IOC_STORE_PATH=/data/threat_intel.db
      - TI_ENABLE_OTX=${TI_ENABLE_OTX:-false}
      - TI_OTX_API_KEY=${TI_OTX_API_KEY}
      - TI_ENABLE_URLHAUS=${TI_ENABLE_URLHAUS:-true}
      - TI_ENABLE_FEODO=${TI_ENABLE_FEODO:-true}
      - TI_ENABLE_PHISHTANK=${TI_ENABLE_PHISHTANK:-true}
    volumes:
      - inventory-data:/data
    restart: unless-stopped
    networks:
      - orion-network

  # Change Monitor Service - Baseline and anomaly detection
  change-monitor:
    image: orion-ai:latest
    container_name: orion-change-monitor
    profiles: ["ai"]
    command: python -m orion_ai.change_monitor.service
    environment:
      - LOKI_URL=${LOKI_URL}
      - CHANGE_MONITOR_INTERVAL_HOURS=${CHANGE_MONITOR_INTERVAL_HOURS:-24}
      - CHANGE_MONITOR_PERIOD_DAYS=${CHANGE_MONITOR_PERIOD_DAYS:-7}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - change-data:/data
    restart: unless-stopped
    networks:
      - orion-network

  # Health Score Service - Security posture scoring
  health-score:
    image: orion-ai:latest
    container_name: orion-health-score
    profiles: ["ai"]
    command: python -m orion_ai.health_score.service
    environment:
      - LOKI_URL=${LOKI_URL}
      - HEALTH_SCORE_INTERVAL_HOURS=${HEALTH_SCORE_INTERVAL_HOURS:-1}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - health-data:/data
    restart: unless-stopped
    networks:
      - orion-network

  # API Server / Web UI - Dashboard and control interface
  # In SPoG mode, exposed via CoreSrv Traefik at https://security.local
  # In standalone mode, accessible at http://localhost:8000
  api:
    image: orion-ai:latest
    container_name: orion-api
    profiles: ["ai"]
    command: python -m orion_ai.ui.http_server
    environment:
      - API_HOST=${API_HOST:-0.0.0.0}
      - API_PORT=${API_PORT:-8000}
      - API_RELOAD=${API_RELOAD:-false}
      - LOKI_URL=${LOKI_URL}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    ports:
      - "${API_PORT:-8000}:8000"
    volumes:
      - inventory-data:/data:ro
    restart: unless-stopped
    depends_on:
      - inventory
    networks:
      - orion-network

  # ============================================================================
  # PROFILE: exporters (Optional - Additional Observability)
  # ============================================================================

  # Process Exporter - Per-process metrics (optional, CPU intensive)
  # Disabled by default - only start if needed for troubleshooting
  # process-exporter:
  #   image: ncabatoff/process-exporter:latest
  #   container_name: orion-process-exporter
  #   profiles: ["exporters"]
  #   privileged: true
  #   volumes:
  #     - /proc:/host/proc:ro
  #   command:
  #     - '--procfs=/host/proc'
  #     - '--children=true'
  #   ports:
  #     - "9256:9256"
  #   restart: unless-stopped
  #   networks:
  #     - orion-network

# ============================================================================
# Volumes
# ============================================================================
#
# NetSec Pi uses NVMe storage via bind mounts (not Docker volumes)
# to avoid wearing out the microSD card and ensure high performance.
#
# AI service volumes (legacy - only used with 'ai' profile)
volumes:
  # AI service volumes (only used if 'ai' profile is enabled)
  soar-data:
    driver: local
  inventory-data:
    driver: local
  change-data:
    driver: local
  health-data:
    driver: local

  # NetSec Tools volumes (only used if 'netsec-tools' profile is enabled)
  redis-data:
    driver: local

# ============================================================================
# Networks
# ============================================================================
networks:
  orion-network:
    driver: bridge
    name: orion-network
